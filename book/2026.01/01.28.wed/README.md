#K8s 전체 아키텍처 개요

컴포즈 단점:한 PC 안에서도 vm이 다르면 통신을 못 함 -> 쿠버네티스가 관리함 : 선언적인 방식

그동안은 두 번 명령하면 두 번 실행됐음, 선언적: "앞으로 6대를 유지해'라고 한번 선언하면 6대가 유지 됨

#### etcd
쿠버네티스는 탐지하는 엔진이 필요, 원격이라서 기기는 서로를 모름 : 나한테 알려주거나, 내가 물어봐야 함 : 이 모듈이 필요함 :etcd가 그 정보들을 다 가지고 있음(주인이 어떻게 유지하라고 선언했는지 알려면 저장해야 하니까)

<img width="1920" height="1080" alt="image" src="https://github.com/user-attachments/assets/a6431cf1-f5fd-479d-a272-2f42f94b7fd1" />

<img width="1920" height="1080" alt="image" src="https://github.com/user-attachments/assets/ec330c63-f142-477a-bd16-8d598f9576f3" />

노드(네트워크에서 온 개념) -> 클라우드로 가면 이것이 가상으로 구현 됨 : PC 한 대에 가상으로 노드들이 생김  
노트:vm , 가상 머신이라고 생각하면 됨:개별적 아이피를 갖고 개별적 서비스를 하게 된 것 -> 온프레미스로 보면 노드 하나다 서버 하나라고 생각하면 됨   

Kubernetes cluster  
얘가 한 vm이 어떤 상태인지 보고 통신 

#### c-m: controler manager    
하나가 죽어도 다른 애들은 일 할 수 있게    

#### api server : 모든 신호의 통로다
이제는 다른 기종간에 연락하는 건 다 api라고 부르고 있음 : 상대편에서는 kubelet이 api한테 알려주는 역할을 함
서로 상태와 어디로 가서 뭘 했는지를 나중에 다시 알 수 있게 하는 연락책 역할 

#### etc : 환경변수들은 여기에 다 있음 +  d : 데몬이라고 생각: 데몬은 지금까지 계속 listen했으면 지금은 watch함
환경변수들 시스템부에는 usr에도 있기도 하고, 업계 특징에 따라 다르게 분산되어 있음    
노드들이 있으면 쿠버네티스는 서비스에는 관심이 없음. 서비스가 돌고 있는지 아닌지만 보면 됨 & 미리 예측해서 손님이 많이 올 것 같을 때 etc에다가 명령이 아니라 ~~라고 유지해 하고 선언해야 하고 넣어둠    
그리고 다른 애들이 api 통해서 전달한 상태도 etcd에 저장하고, 명령들도 다 etcd에 저장함     
앞으로의 계획도 etcd에 저장해 둠   

#### kube-scheduler : 앞으로의 계획을 세움   

#### c-c-m: 내부에 간단하게 역할을 나눔
클라우드도 소식을 받고 지시를 내리고 해야 하기 때문에   

#### k-proxy : 네트워크 담당임 
앞에서의 그냥 프록시는 출발지를 모르게 하는 거: 나를 숨기는 거, 역프록시는 목적지를 모르는 거: 내가 도착지를 몰라서 앞에 있는 프록시 서버가 나한테 물어봐~하고 알려주는 거       
노드는 가상의 그래픽 카드를 가짐(가장의 인터페이스) 그런 것 들을 가정 해 둠    
+ 앞의 파트에서는 죽었는지 안죽었는지만 봄, 협업하는 친구들의 아이피 정보까지 프록시가 가지고 있음 : 그래서 닉이라고 이름짓지 않는 듯

쿠보네티스는 운영하는 것, 모든 애들은 api를 통해 메시지를 주고 받고,(모든 정보들은 etc 뒤에 데이터베이스화 해서 etcd에 저장해둠:관리자가 선언해둔 것을), 나머지 데몬들은 여기를 들여다 보고, 정보대로 할 일을 함.    
그 일을 하는 것은 control manager,scheduler가 etc를 보고 계획,구성함   

노드에는 내 상태를 api한테 알려줘야 해서 대표인 kubelet이 하나 있음     
누가 뭘 하는 지, 어떤지를 자기 아이피 네트워크 정보와 함께 협업하는 애들의 네트워크 정보까지 가지고 있음

<img width="1920" height="1080" alt="image" src="https://github.com/user-attachments/assets/ab21098c-2dfc-499f-81ff-70229650234e" />
위의 설명을 어렵게 표시한 게 이것   

#### Control Plane
개발자가 etc한테 알려줘도 되지만, "etc한테 이거 알려줘~ 좀 있으면 추석이니까 ~~이렇게 선언해"를  API한테 다 줘서 etcd에 저장해 둠   

Cloud Controller Manager는 옵션임 클라우드가 있을 때만   

각 VM마다 얘네를 VM이라고 부름. 쿠버네티스가 안 깔려 있을 땐 노드라고 부르지 않음. 지금은 노드 두개만 뒀음

Kubelet이 제일 앞에서 연락을 받음.   

Containerd는 Docker가 했음. 도커는 쿠버네티스가 아님. 도커는 컨테이너를 빌드하고 런하는 애   
쿠버네티스는 빌드하고 런하지 않음(엄격히 얘기하면 안 함)   
:containerd는 엄격히는 쿠버네티스가 아니지만 도커가 없을 때 쿠버네티스 쓰려면 깔아야 함   
:nerdctl라는 게 있음   : 이전의 docker build를 nerdctl build가 완전히 대체 가능해서 이제 '쿠버네티스가 다 할 수 있다'고 말 하는 것   

도커 파일은 이미지를 만들고, 이미지를 실행시키면 컨테이너. -> 하나의 vm 안에 여러개의 컨테이너를 관리하려고 쿠버네티스 -> 여러 서비스도 묶을 수 있음   ex) 전세계 서비스 하려면 db서버도 여러대 묶어놔야 함   
국가별, 리젼 별로 2-3대 두고 쉬는 시간에 정보를 비교해서 맞춤(합침):안 맞출 수도 있음: 그 국가의 리젼 db한테 물어봐서 가져오게 함 : 유저는 몰라도 되니까   
내부적으로는 2-3대가 적당(너무 많으면 맞추기가 힘드니까)    

데이터는 연도별로 db를 따로 두기도 함 : 대표적으로 금융권    
1년 이후 것의 정보만 저장 해 둔 db서버에 접속하는 버튼을 아예 분리해서 사용함    

각 노드 마다 서비스 하려던 웹서버 파드가 있음 : 쿠보네티스에서 관리하는 가장 작은 단위로 컨테이너가 여러대 있음(관리하기 좋게 몇 대 죽었는지 확인해서 늘리고줄임)      

#### 클러스터:
네트워크 할 때는 비슷한 것 끼리 쫙 모아두는 것 : 아이피만 다르지 똑같은 일 하는 애들


